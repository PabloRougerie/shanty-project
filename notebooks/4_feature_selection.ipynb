{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3975a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from ml_logic.data_preprocessing import clean_data, resample_pings\n",
    "from ml_logic.feature_engineering import create_time_series_features\n",
    "from ml_logic.metric import position_extrapolation, haversine_mae\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7188d",
   "metadata": {},
   "source": [
    "# Feature Selection Analysis\n",
    "\n",
    "## Objective\n",
    "\n",
    "After feature engineering showed no improvement, we now test whether **feature selection** can:\n",
    "1. Identify redundant or harmful features\n",
    "2. Improve model performance by removing noise\n",
    "3. Reduce model complexity without losing predictive power\n",
    "\n",
    "**Method**: Permutation importance with cross-validation.\n",
    "\n",
    "**Hypothesis**: Some lag features (especially long-term COG/SOG lags) might be redundant or noisy, and removing them could improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ad00d",
   "metadata": {},
   "source": [
    "We use **480 minutes (8 hours)** as the target horizon because:\n",
    "- This is where ML models start to significantly outperform the baseline (see notebook 3)\n",
    "- It represents a good balance between short-term (where baseline dominates) and long-term predictions\n",
    "- Feature importance patterns are most relevant at this horizon where ML provides value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb9ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target prediction horizon: 480 min. Number of steps: 96\n",
      "Defining lag windows of 80min, 240min, 480min\n"
     ]
    }
   ],
   "source": [
    "## 1. Data Preparation\n",
    "df = pd.read_parquet(\"../data/processed/ais_filtered.parquet\")\n",
    "df = clean_data(df) #remove missing values and clean\n",
    "df = resample_pings(df, interval='5min') #uniformize pings\n",
    "\n",
    "#choice of 480min as time horizon : time where ML-approche provide improvement\n",
    "df_lag = create_time_series_features(df, target_horizon= 480,\n",
    "                                     rolling= False,\n",
    "                                     advanced_features= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d449e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate X,y and groups for split\n",
    "X = df_lag.drop(columns=[\"MMSI\", \"BaseDateTime\", \"target_LAT\", \"target_LON\"])\n",
    "y = df_lag[[\"target_LAT\", \"target_LON\"]]\n",
    "groups = df_lag[\"MMSI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18716cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 748405 samples, 729 vessels\n",
      "Test: 180459 samples, 183 vessels\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train/test split respecting MMSI groups\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=273)\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    #need to isolate a group on the train set for future crossval\n",
    "    groups_train = groups.iloc[train_idx]\n",
    "    groups_test = groups.iloc[test_idx]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples, {groups_train.nunique()} vessels\")\n",
    "print(f\"Test: {len(X_test)} samples, {groups_test.nunique()} vessels\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bdfe223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model to use for permutation\n",
    "estimators = {\n",
    "    \"Ridge_scaled\": Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('model', Ridge(alpha=1.0))\n",
    "    ]),\n",
    "    \"LightGBM\": LGBMRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=273,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "importance_df = pd.DataFrame(index=X_train.columns) #df to stock results of permutation\n",
    "haversine_scorer = make_scorer(haversine_mae, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc470f",
   "metadata": {},
   "source": [
    "## 2. Permutation Importance Analysis\n",
    "\n",
    "### 2.1 LightGBM: Cross-validation + Permutation Importance\n",
    "\n",
    "We use **GroupKFold** (5 folds) to ensure no data leakage: each vessel's data stays together in train or validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e1445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LON</td>\n",
       "      <td>266.245483</td>\n",
       "      <td>20.253742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAT</td>\n",
       "      <td>55.458805</td>\n",
       "      <td>4.009232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LON_lag_80min</td>\n",
       "      <td>46.695315</td>\n",
       "      <td>1.972898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LAT_lag_80min</td>\n",
       "      <td>15.278227</td>\n",
       "      <td>2.084895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LON_lag_480min</td>\n",
       "      <td>10.714924</td>\n",
       "      <td>2.770576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LAT_lag_240min</td>\n",
       "      <td>8.653096</td>\n",
       "      <td>1.900738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LON_lag_240min</td>\n",
       "      <td>8.270339</td>\n",
       "      <td>1.455316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOG</td>\n",
       "      <td>4.842158</td>\n",
       "      <td>0.464616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LAT_lag_480min</td>\n",
       "      <td>4.662294</td>\n",
       "      <td>0.344370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Length</td>\n",
       "      <td>2.558887</td>\n",
       "      <td>0.922419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Draft</td>\n",
       "      <td>1.966479</td>\n",
       "      <td>0.802266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Width</td>\n",
       "      <td>1.637591</td>\n",
       "      <td>0.249438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heading</td>\n",
       "      <td>1.357797</td>\n",
       "      <td>0.345043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Status</td>\n",
       "      <td>1.226473</td>\n",
       "      <td>0.282522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COG</td>\n",
       "      <td>1.147825</td>\n",
       "      <td>0.093020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SOG_lag_80min</td>\n",
       "      <td>0.279269</td>\n",
       "      <td>0.165928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SOG_lag_240min</td>\n",
       "      <td>0.170667</td>\n",
       "      <td>0.077769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SOG_lag_480min</td>\n",
       "      <td>0.145037</td>\n",
       "      <td>0.136493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>COG_lag_240min</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.033958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>COG_lag_80min</td>\n",
       "      <td>-0.011749</td>\n",
       "      <td>0.061612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>COG_lag_480min</td>\n",
       "      <td>-0.020052</td>\n",
       "      <td>0.057468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance_mean  importance_std\n",
       "1              LON       266.245483       20.253742\n",
       "0              LAT        55.458805        4.009232\n",
       "12   LON_lag_80min        46.695315        1.972898\n",
       "9    LAT_lag_80min        15.278227        2.084895\n",
       "14  LON_lag_480min        10.714924        2.770576\n",
       "10  LAT_lag_240min         8.653096        1.900738\n",
       "13  LON_lag_240min         8.270339        1.455316\n",
       "2              SOG         4.842158        0.464616\n",
       "11  LAT_lag_480min         4.662294        0.344370\n",
       "6           Length         2.558887        0.922419\n",
       "8            Draft         1.966479        0.802266\n",
       "7            Width         1.637591        0.249438\n",
       "4          Heading         1.357797        0.345043\n",
       "5           Status         1.226473        0.282522\n",
       "3              COG         1.147825        0.093020\n",
       "15   SOG_lag_80min         0.279269        0.165928\n",
       "16  SOG_lag_240min         0.170667        0.077769\n",
       "17  SOG_lag_480min         0.145037        0.136493\n",
       "19  COG_lag_240min         0.006937        0.033958\n",
       "18   COG_lag_80min        -0.011749        0.061612\n",
       "20  COG_lag_480min        -0.020052        0.057468"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_importance = [] #list to stock scores in each fold\n",
    "gkf = GroupKFold(n_splits= 5) #for crossval respecting MMSI\n",
    "\n",
    "#generating folds without cutting through a single boat ping sequence\n",
    "for fold_idx, (train_fold_idx, val_fold_idx) in enumerate(gkf.split(X_train, y_train, groups= groups_train)):\n",
    "    print(f\"  Fold {fold_idx + 1}/5\")\n",
    "    #generating the train and val sets\n",
    "    X_train_fold = X_train.iloc[train_fold_idx]\n",
    "    X_val_fold = X_train.iloc[val_fold_idx]\n",
    "    y_train_fold = y_train.iloc[train_fold_idx]\n",
    "    y_val_fold = y_train.iloc[val_fold_idx]\n",
    "\n",
    "\n",
    "    model_fold = MultiOutputRegressor(estimators[\"LightGBM\"])\n",
    "    model_fold.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Permutation importance on validation fold\n",
    "    importance = permutation_importance(\n",
    "        model_fold, X_val_fold, y_val_fold,\n",
    "        n_repeats=6,\n",
    "        random_state=273,\n",
    "        scoring=haversine_scorer,\n",
    "        n_jobs= -1)\n",
    "\n",
    "    #list of lists (each list contains the means of the 6 MAE scores of permutation, for each featutre)\n",
    "    fold_importance.append(importance.importances_mean)\n",
    "\n",
    "fold_importance = np.array(fold_importance) #conversion in 2D array shape (5, n_features)\n",
    "\n",
    "importance_df = pd.DataFrame({\"feature\": X_train.columns,\n",
    "                              \"importance_mean\": fold_importance.mean(axis= 0),\n",
    "                              \"importance_std\": fold_importance.std(axis= 0)\n",
    "                              }).sort_values(by=\"importance_mean\",  ascending= False)\n",
    "\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315d5ba",
   "metadata": {},
   "source": [
    "**Key observations**:\n",
    "- Position features (LAT, LON) and their lags dominate importance\n",
    "- Vessel dimensions (Length, Width, Draft) have moderate importance\n",
    "- Some COG/SOG lags show very low or negative importance (harmful features)\n",
    "- Negative importance means the feature actually hurts performance when shuffled (model performs better with noise!)\n",
    "\n",
    "**Next step**: Compare with Ridge to find consensus on which features to remove.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9fc79",
   "metadata": {},
   "source": [
    "### 2.2 Ridge: Cross-validation + Permutation Importance\n",
    "\n",
    "Same methodology as LightGBM to compare feature importance patterns between linear and tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82f9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LON</td>\n",
       "      <td>921.961766</td>\n",
       "      <td>86.917275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LON_lag_80min</td>\n",
       "      <td>440.530894</td>\n",
       "      <td>37.958254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAT</td>\n",
       "      <td>227.217915</td>\n",
       "      <td>8.030887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LON_lag_240min</td>\n",
       "      <td>130.169964</td>\n",
       "      <td>22.573591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LAT_lag_80min</td>\n",
       "      <td>111.434943</td>\n",
       "      <td>7.517471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LAT_lag_240min</td>\n",
       "      <td>36.356315</td>\n",
       "      <td>4.368273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LON_lag_480min</td>\n",
       "      <td>25.372544</td>\n",
       "      <td>2.655244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LAT_lag_480min</td>\n",
       "      <td>6.252056</td>\n",
       "      <td>0.778376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SOG_lag_80min</td>\n",
       "      <td>1.466589</td>\n",
       "      <td>0.809965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Length</td>\n",
       "      <td>1.352245</td>\n",
       "      <td>0.320931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SOG_lag_480min</td>\n",
       "      <td>1.182890</td>\n",
       "      <td>1.033583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOG</td>\n",
       "      <td>0.698538</td>\n",
       "      <td>0.374731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Width</td>\n",
       "      <td>0.502137</td>\n",
       "      <td>0.194439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COG</td>\n",
       "      <td>0.340523</td>\n",
       "      <td>0.059376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Draft</td>\n",
       "      <td>0.311563</td>\n",
       "      <td>0.118228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>COG_lag_80min</td>\n",
       "      <td>0.117206</td>\n",
       "      <td>0.021187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SOG_lag_240min</td>\n",
       "      <td>0.058069</td>\n",
       "      <td>0.125805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>COG_lag_240min</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.009615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>COG_lag_480min</td>\n",
       "      <td>0.012079</td>\n",
       "      <td>0.004987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heading</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>0.019097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Status</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.032814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance_mean  importance_std\n",
       "1              LON       921.961766       86.917275\n",
       "12   LON_lag_80min       440.530894       37.958254\n",
       "0              LAT       227.217915        8.030887\n",
       "13  LON_lag_240min       130.169964       22.573591\n",
       "9    LAT_lag_80min       111.434943        7.517471\n",
       "10  LAT_lag_240min        36.356315        4.368273\n",
       "14  LON_lag_480min        25.372544        2.655244\n",
       "11  LAT_lag_480min         6.252056        0.778376\n",
       "15   SOG_lag_80min         1.466589        0.809965\n",
       "6           Length         1.352245        0.320931\n",
       "17  SOG_lag_480min         1.182890        1.033583\n",
       "2              SOG         0.698538        0.374731\n",
       "7            Width         0.502137        0.194439\n",
       "3              COG         0.340523        0.059376\n",
       "8            Draft         0.311563        0.118228\n",
       "18   COG_lag_80min         0.117206        0.021187\n",
       "16  SOG_lag_240min         0.058069        0.125805\n",
       "19  COG_lag_240min         0.028389        0.009615\n",
       "20  COG_lag_480min         0.012079        0.004987\n",
       "4          Heading         0.011695        0.019097\n",
       "5           Status         0.004933        0.032814"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_importance = []\n",
    "gkf = GroupKFold(n_splits= 5)\n",
    "for fold_idx, (train_fold_idx, val_fold_idx) in enumerate(gkf.split(X_train, y_train, groups= groups_train)):\n",
    "    print(f\"  Fold {fold_idx + 1}/5\")\n",
    "    X_train_fold = X_train.iloc[train_fold_idx]\n",
    "    X_val_fold = X_train.iloc[val_fold_idx]\n",
    "    y_train_fold = y_train.iloc[train_fold_idx]\n",
    "    y_val_fold = y_train.iloc[val_fold_idx]\n",
    "\n",
    "\n",
    "    model_fold = MultiOutputRegressor(estimators[\"Ridge_scaled\"])\n",
    "    model_fold.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Permutation importance on validation fold\n",
    "    importance = permutation_importance(\n",
    "        model_fold, X_val_fold, y_val_fold,\n",
    "        n_repeats=6,\n",
    "        random_state=273,\n",
    "        scoring=haversine_scorer,\n",
    "        n_jobs= -1)\n",
    "\n",
    "    fold_importance.append(importance.importances_mean)\n",
    "\n",
    "fold_importance = np.array(fold_importance)\n",
    "importance_df_ridge = pd.DataFrame({\"feature\": X_train.columns,\n",
    "                              \"importance_mean\": fold_importance.mean(axis= 0),\n",
    "                              \"importance_std\": fold_importance.std(axis= 0)\n",
    "                              }).sort_values(by=\"importance_mean\",  ascending= False)\n",
    "\n",
    "importance_df_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e6d4ca",
   "metadata": {},
   "source": [
    "### Interpretation: Ridge Permutation Importance\n",
    "\n",
    "**Comparison with LightGBM**:\n",
    "- Ridge shows similar patterns but with different magnitudes (linear model vs tree-based)\n",
    "- Both models agree on which features are least important\n",
    "- Consensus features to remove: `COG_lag_240min`, `COG_lag_480min`, `SOG_lag_240min`\n",
    "\n",
    "**Why these features?**\n",
    "- Long-term COG lags (240min, 480min) are less predictive than position lags\n",
    "- SOG at 240min is redundant with other SOG lags\n",
    "- These features may introduce noise without adding signal\n",
    "\n",
    "**Decision**: Remove the 3 consensus low-importance features and test impact via cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951c1b3",
   "metadata": {},
   "source": [
    "## 3. Feature Selection Validation\n",
    "\n",
    "We remove the 3 consensus low-importance features identified by both models and validate the impact via cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b694976",
   "metadata": {},
   "source": [
    "#### Test with selected features with LGBM model (crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3503a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 3 features: ['COG_lag_240min', 'COG_lag_480min', 'SOG_lag_240min']\n"
     ]
    }
   ],
   "source": [
    "# Removing features with negative or very low importance on both models\n",
    "features_to_remove = ['COG_lag_240min', 'COG_lag_480min','SOG_lag_240min']\n",
    "features_to_keep = [f for f in X_train.columns if f not in features_to_remove]\n",
    "\n",
    "print(f\"Removing {len(features_to_remove)} features: {features_to_remove}\")\n",
    "\n",
    "# Create datasets with selected features\n",
    "X_train_selected = X_train[features_to_keep]\n",
    "X_test_selected = X_test[features_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27f79f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "  With all features\n",
      "  With selected features...\n",
      "\n",
      "  MAE with all features: 20.314 ± 1.655 km\n",
      "  MAE with selected features: 20.047 ± 2.076 km\n",
      "  Improvement: 1.32%\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation comparison: all features vs selected features\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Define LightGBM parameters (reusable for CV and final model)\n",
    "lgbm_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 273,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Test LightGBM\n",
    "print(\"LightGBM\")\n",
    "\n",
    "# With all features (separate instance for CV)\n",
    "print(\"  With all features\")\n",
    "lgbm_cv_all = LGBMRegressor(**lgbm_params)\n",
    "scores_all = cross_val_score(\n",
    "    MultiOutputRegressor(lgbm_cv_all),\n",
    "    X_train, y_train,\n",
    "    cv=gkf,\n",
    "    groups=groups_train,\n",
    "    scoring=haversine_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# With selected features (separate instance for CV)\n",
    "print(\"  With selected features...\")\n",
    "lgbm_cv_selected = LGBMRegressor(**lgbm_params)\n",
    "scores_selected = cross_val_score(\n",
    "    MultiOutputRegressor(lgbm_cv_selected),\n",
    "    X_train_selected, y_train,\n",
    "    cv=gkf,\n",
    "    groups=groups_train,\n",
    "    scoring=haversine_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "mae_all = -scores_all.mean() #negative bc sklearn negativates the metric\n",
    "mae_selected = -scores_selected.mean()\n",
    "improvement = ((mae_all - mae_selected) / mae_all) * 100\n",
    "\n",
    "print(f\"\\n  MAE with all features: {mae_all:.3f} ± {scores_all.std():.3f} km\")\n",
    "print(f\"  MAE with selected features: {mae_selected:.3f} ± {scores_selected.std():.3f} km\")\n",
    "print(f\"  Improvement: {improvement:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9004f5",
   "metadata": {},
   "source": [
    "#### Test with selected features on Ridge model (crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38109fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge (scaled):\n",
      "  With all features...\n",
      "  With selected features...\n",
      "\n",
      "  MAE with all features: 20.191 ± 1.221 km\n",
      "  MAE with selected features: 20.184 ± 1.224 km\n",
      "  Improvement: 0.03%\n"
     ]
    }
   ],
   "source": [
    "# Test Ridge with scaling\n",
    "print(\"\\nRidge (scaled):\")\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('model', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "# With all features\n",
    "print(\"  With all features...\")\n",
    "scores_ridge_all = cross_val_score(\n",
    "    MultiOutputRegressor(ridge_pipeline),\n",
    "    X_train, y_train,\n",
    "    cv=gkf,\n",
    "    groups=groups_train,\n",
    "    scoring=haversine_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# With selected features\n",
    "print(\"  With selected features...\")\n",
    "scores_ridge_selected = cross_val_score(\n",
    "    MultiOutputRegressor(ridge_pipeline),\n",
    "    X_train_selected, y_train,\n",
    "    cv=gkf,\n",
    "    groups=groups_train,\n",
    "    scoring=haversine_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "mae_ridge_all = -scores_ridge_all.mean()\n",
    "mae_ridge_selected = -scores_ridge_selected.mean()\n",
    "improvement_ridge = ((mae_ridge_all - mae_ridge_selected) / mae_ridge_all) * 100\n",
    "\n",
    "print(f\"\\n  MAE with all features: {mae_ridge_all:.3f} ± {scores_ridge_all.std():.3f} km\")\n",
    "print(f\"  MAE with selected features: {mae_ridge_selected:.3f} ± {scores_ridge_selected.std():.3f} km\")\n",
    "print(f\"  Improvement: {improvement_ridge:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b25465",
   "metadata": {},
   "source": [
    "### Interpretation: Feature Selection Impact\n",
    "\n",
    "**Results**:\n",
    "- **LightGBM**: Small improvement (+1.32%) with selected features\n",
    "- **Ridge**: Negligible improvement (+0.03%) with selected features\n",
    "\n",
    "**Analysis**:\n",
    "- Removing 3 low-importance features slightly improves LightGBM (reduces overfitting)\n",
    "- Ridge is less sensitive to feature removal (linear model, less prone to overfitting)\n",
    "- The improvement is minimal but consistent with our hypothesis\n",
    "\n",
    "**Conclusion**: Feature selection provides marginal benefit. The removed features were indeed redundant, but the base feature set was already well-optimized. We proceed with selected features for the final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb062c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overall Feature Selection Conclusion\n",
    "\n",
    "\n",
    "- **Feature selection works** but provides marginal gains (~1%)\n",
    "- The base feature set was already well-designed (simple lag features are optimal)\n",
    "- Removing  helps tree-based models (LightGBM) more than linear models (Ridge)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "***Proceed to hyperparameter tuning (notebook 5) with the selected feature set to further optimize model performance.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20b7ec",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vessel_tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
